# 実用プロンプト例集

## 📋 概要

本ドキュメントは、Azure Data Factoryプロジェクトの機能拡張において実際に使用できる具体的なプロンプト例を提供します。

---

## 🎯 使用シナリオ別プロンプト例

### シナリオ1: 新規データパイプライン追加

#### プロンプト例: "顧客満足度分析パイプライン"

```markdown
## 新機能要求: 顧客満足度分析パイプライン

### ビジネス要件
**背景**: 
マーケティング部門から、顧客満足度調査データを自動分析し、リアルタイムでダッシュボードに反映させたいという要求があります。現在は手作業でExcel分析を行っており、週次でのレポート作成に3日かかっています。

**期待効果**:
- 分析作業時間を90%削減（3日 → 0.5日）
- リアルタイムでの顧客満足度トレンド把握
- 問題顧客の早期発見による解約防止

### 機能仕様
**入力データ**:
- 顧客満足度調査CSV（毎日 9:00に Blob Storage に配置）
- 顧客マスターデータ（SQL Database）
- 製品マスターデータ（SQL Database）

**処理内容**:
1. CSV データの取得・検証
2. 顧客マスター・製品マスターとの結合
3. 満足度スコア計算（加重平均）
4. 異常値・外れ値の検出
5. トレンド分析（前月比較）
6. ダッシュボード用データマート更新

**出力データ**:
- 顧客満足度サマリーテーブル
- 異常検知アラートテーブル
- Power BI用データマート

### 非機能要件
- **処理時間**: 10,000件のデータを30分以内
- **可用性**: 99.5%（月次メンテナンス除く）
- **エラー処理**: 異常データは隔離し、処理継続
- **監視**: 処理状況をSlackに通知

### 技術制約
- 既存のSQL Server 2022を使用
- Azure Data Factory v2の既存環境
- Power BI Premium容量の制限内
```

**対応するドメインモデル設計指示**:
```markdown
上記の顧客満足度分析パイプライン要件に基づき、以下を設計してください：

1. **ドメインモデル拡張**:
   - 既存の「パイプライン実行ドメイン」内で実装するか、新規「顧客分析ドメイン」を作成するかを判断
   - Customer Satisfaction エンティティの設計
   - Satisfaction Score 値オブジェクトの設計
   - Anomaly Detection ドメインサービスの設計

2. **パイプライン設計**:
   - パイプライン名: pipeline_customer_satisfaction_analysis
   - Copy Activity: Blob → SQL Database
   - Data Flow: 満足度スコア計算ロジック
   - Stored Procedure Activity: 異常検知処理

3. **テスト設計**:
   - 正常系: 標準的な満足度データ処理
   - 異常系: 不正データ、欠損データ処理
   - 境界値: 最大・最小データ量での処理
```

### シナリオ2: データ品質監視機能拡張

#### プロンプト例: "データドリフト検知機能"

```markdown
## 機能拡張要求: データドリフト検知機能

### 背景・課題
現在のデータ品質チェックは静的なルールベースですが、データの分布や傾向の変化（データドリフト）を検知する仕組みがありません。機械学習モデルの精度低下や、ビジネス指標の異常な変動を早期に発見したいです。

### 機能要件
**検知対象**:
- 数値データの分布変化（平均、分散、歪度）
- カテゴリカルデータの出現頻度変化
- 時系列データのトレンド変化
- データスキーマの変更（列追加・削除・型変更）

**検知アルゴリズム**:
- Statistical Test（KS検定、Chi-square検定）
- Information-theoretic（KLダイバージェンス）
- Distance-based（Earth Mover's Distance）

**アラート条件**:
- 変化度がしきい値を超過
- 連続して異常が検出（3回連続）
- 複数の指標で同時に異常

### 技術要件
**アーキテクチャ**:
- 既存の「データ品質保証ドメイン」を拡張
- リアルタイム検知とバッチ検知の両方
- MLOps パイプラインとの連携

**実装方針**:
- Python Azure Functions での検知ロジック
- Azure Machine Learning でのモデル管理
- Application Insights でのメトリクス可視化
```

### シナリオ3: テスト自動化強化

#### プロンプト例: "カオスエンジニアリングテスト"

```markdown
## テスト拡張要求: カオスエンジニアリングテスト導入

### 目的
本番環境での障害復旧力（Resilience）を向上させるため、意図的に障害を発生させるカオスエンジニアリングテストを導入したいです。

### テストシナリオ
**インフラストラクチャ障害**:
- SQL Server 接続タイムアウト
- Blob Storage 一時的アクセス不可
- Integration Runtime ダウン

**データ障害**:
- 不正フォーマットデータ投入
- 大量データ突発的投入
- 重複データ投入

**ネットワーク障害**:
- 高レイテンシ環境
- パケットロス環境
- 帯域幅制限

### 期待結果
- 自動復旧機能の動作確認
- アラート・通知の適切な発火
- データ整合性の維持確認
- パフォーマンス劣化の許容範囲確認

### 実装要件
- 非本番環境での安全な実行
- テスト結果の自動レポート生成
- CI/CDパイプラインへの組み込み
```

---

## 🚀 段階的実装プロンプト例

### フェーズ1: MVP（最小実行可能製品）

```markdown
## MVP実装指示

**目標**: 2週間で基本機能を実装し、早期フィードバックを獲得

**実装範囲**:
1. **基本パイプライン**:
   - 単純なCopy Activity
   - 基本的なエラーハンドリング
   - 成功・失敗の通知のみ

2. **最小限のテスト**:
   - 正常系のE2Eテスト1ケース
   - 基本的な単体テスト

3. **簡易ドキュメント**:
   - 実行手順書
   - 基本的なトラブルシューティング

**除外事項**:
- 高度なエラー処理
- パフォーマンス最適化
- 詳細な監視・ログ
```

### フェーズ2: 本格実装

```markdown
## 本格実装指示

**前提**: MVP での学習とフィードバックを反映

**追加実装**:
1. **エラー処理強化**:
   - リトライ機構
   - 部分失敗時の継続処理
   - デッドレター対応

2. **監視・ログ強化**:
   - 詳細なパフォーマンスメトリクス
   - ビジネスメトリクス追跡
   - 異常検知アラート

3. **テスト強化**:
   - 異常系テストケース追加
   - パフォーマンステスト
   - セキュリティテスト

4. **運用対応**:
   - 運用手順書
   - 監視ダッシュボード
   - インシデント対応手順
```

---

## 🔧 特定技術向けプロンプト例

### Azure Functions統合

```markdown
## Azure Functions統合要求

**統合目的**: 
既存のADFパイプラインにカスタムロジックを追加するため、Azure Functionsとの連携を実現したいです。

**技術要件**:
- HTTP Trigger での ADF からの呼び出し
- Durable Functions での長時間処理
- Application Insights でのトレーシング連携

**実装指示**:
1. **Function App 設計**:
   - ドメインサービスロジックをFunction化
   - 既存のPythonコードベースを活用
   - 環境変数による設定外部化

2. **ADF統合**:
   - Azure Function Activity の追加
   - エラーハンドリングの統一
   - ログ・メトリクス収集の統合

3. **テスト戦略**:
   - Function単体のテスト
   - ADF-Function統合テスト
   - エンドツーエンドテスト
```

### Machine Learning統合

```markdown
## Azure ML統合要求

**統合目的**: 
データ処理パイプラインに機械学習による予測・分類機能を組み込みたいです。

**ML要件**:
- 顧客解約予測モデル
- 異常検知モデル
- レコメンデーションモデル

**技術統合**:
1. **モデルデプロイ**:
   - Azure ML Endpoint での推論API
   - ADF での REST API 呼び出し
   - バッチ推論とリアルタイム推論

2. **MLOps統合**:
   - モデル再訓練パイプライン
   - A/Bテスト機能
   - モデルドリフト検知

3. **データフロー**:
   - 特徴量エンジニアリング
   - 予測結果の後処理
   - フィードバックループ
```

---

## 📊 成功指標定義プロンプト

### KPI設定

```markdown
## 機能追加後のKPI定義

**開発効率KPI**:
- 実装速度: ストーリーポイント/スプリント
- 品質: バグ密度（バグ数/KLOC）
- テストカバレッジ: 90%以上維持

**運用効率KPI**:
- パイプライン成功率: 99.5%以上
- 平均処理時間: ベースライン比20%改善
- インシデント解決時間: 4時間以内

**ビジネス価値KPI**:
- 処理自動化率: 手作業時間90%削減
- データ精度: 品質スコア95%以上
- ユーザー満足度: Net Promoter Score 8以上

### 測定方法
**自動測定**:
- Azure Monitor でのメトリクス収集
- Application Insights でのカスタムイベント
- Power BI でのダッシュボード可視化

**手動測定**:
- 月次ユーザーアンケート
- 四半期ビジネスレビュー
- 年次ROI計算
```

---

## 🎯 プロンプト実行チェックリスト

### 要件定義フェーズ
- [ ] ビジネス課題の具体的記述
- [ ] ステークホルダーの明確化
- [ ] 成功指標の定量化
- [ ] 制約条件の網羅
- [ ] 受け入れ基準の明確化

### 設計フェーズ
- [ ] ドメインモデルとの整合性確認
- [ ] 既存アーキテクチャとの適合性評価
- [ ] セキュリティ要件の考慮
- [ ] パフォーマンス要件の明確化
- [ ] 運用・保守性の考慮

### 実装フェーズ
- [ ] 実装優先順位の明確化
- [ ] テスト戦略の具体化
- [ ] コードレビュー基準の確認
- [ ] CI/CD統合計画の策定
- [ ] ドキュメント更新計画の確認

---

**更新日**: 2025年7月5日  
**作成者**: プロンプト設計チーム  
**承認者**: アーキテクチャレビューボード
